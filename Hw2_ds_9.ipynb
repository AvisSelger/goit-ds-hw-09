{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading a two-dimensional dataset\n",
    "data_2d = pd.read_csv('C:\\Users\\copik\\OneDrive\\Рабочий стол\\data.zip\\data_2d.csv')\n",
    "data_2d.head()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Defining the range of the number of clusters\n",
    "range_n_clusters = range(1, 11)\n",
    "\n",
    "# Calculate the sum of the squares of the distances to the nearest centroid\n",
    "sse = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(data_2d)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Graphing the elbow method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, sse, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters (2D Data)')\n",
    "plt.show()\n",
    "\n",
    "# Defining the range of the number of clusters\n",
    "range_n_clusters = range(1, 11)\n",
    "\n",
    "# Calculating the sum of squares of distances to the nearest centroid for MNIST\n",
    "sse_mnist = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(mnist_data)\n",
    "    sse_mnist.append(kmeans.inertia_)\n",
    "\n",
    "# Building a graph of the elbow method for MNIST\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, sse_mnist, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters (MNIST Data)')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a two-dimensional dataset\n",
    "data_2d = pd.read_csv('/mnt/data/data_2d.csv')\n",
    "\n",
    "# Using K-means with the optimal number of clusters (for example, 3)\n",
    "optimal_clusters_2d = 3\n",
    "kmeans_2d = KMeans(n_clusters=optimal_clusters_2d, random_state=42)\n",
    "data_2d['Cluster'] = kmeans_2d.fit_predict(data_2d)\n",
    "\n",
    "# Visualization of the clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_2d.iloc[:, 0], data_2d.iloc[:, 1], c=data_2d['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-means Clustering (2D Data)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Loading MNIST dataset\n",
    "mnist_data = pd.read_csv('/mnt/data/mnist.csv')\n",
    "\n",
    "# Dimensionality reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "mnist_2d = pca.fit_transform(mnist_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K-means with the optimal number of clusters (for example, 4)\n",
    "optimal_clusters_mnist = 4\n",
    "kmeans_mnist = KMeans(n_clusters=optimal_clusters_mnist, random_state=42)\n",
    "clusters_mnist = kmeans_mnist.fit_predict(mnist_2d)\n",
    "\n",
    "# Visualization of the clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(mnist_2d[:, 0], mnist_2d[:, 1], c=clusters_mnist, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-means Clustering (MNIST Data reduced with PCA)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a two-dimensional dataset\n",
    "data_2d = pd.read_csv('/mnt/data/data_2d.csv')\n",
    "\n",
    "# Using K-means with the optimal number of clusters (for example, 3)\n",
    "optimal_clusters_2d = 3\n",
    "kmeans_2d = KMeans(n_clusters=optimal_clusters_2d, random_state=42)\n",
    "data_2d['Cluster'] = kmeans_2d.fit_predict(data_2d)\n",
    "\n",
    "# Visualizing clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_2d.iloc[:, 0], data_2d.iloc[:, 1], c=data_2d['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-means Clustering (2D Data)')\n",
    "plt.show()\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist_data = pd.read_csv('/mnt/data/mnist.csv')\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=2)\n",
    "mnist_2d = pca.fit_transform(mnist_data)\n",
    "\n",
    "# Visualizing clustering\n",
    "optimal_clusters_mnist = 4\n",
    "kmeans_mnist = KMeans(n_clusters=optimal_clusters_mnist, random_state=42)\n",
    "clusters_mnist = kmeans_mnist.fit_predict(mnist_2d)\n",
    "\n",
    "# Visualizing clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(mnist_2d[:, 0], mnist_2d[:, 1], c=clusters_mnist, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-means Clustering (MNIST Data reduced with PCA)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a two-dimensional dataset\n",
    "data_2d = pd.read_csv('data_2d.csv')\n",
    "\n",
    "# Using K-means with the optimal number of clusters (for example, 3)\n",
    "optimal_clusters_2d = 3\n",
    "kmeans_2d = KMeans(n_clusters=optimal_clusters_2d, random_state=42)\n",
    "data_2d['Cluster'] = kmeans_2d.fit_predict(data_2d)\n",
    "\n",
    "# Visualization of clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data_2d.iloc[:, 0], data_2d.iloc[:, 1], c=data_2d['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-means Clustering (2D Data)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset\n",
    "mnist_data = pd.read_csv('mnist.csv')\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=2)\n",
    "mnist_2d = pca.fit_transform(mnist_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K-means with the optimal number of clusters (for example, 4)\n",
    "optimal_clusters_mnist = 4\n",
    "kmeans_mnist = KMeans(n_clusters=optimal_clusters_mnist, random_state=42)\n",
    "clusters_mnist = kmeans_mnist.fit_predict(mnist_2d)\n",
    "\n",
    "# Visualization of clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(mnist_2d[:, 0], mnist_2d[:, 1], c=clusters_mnist, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-means Clustering (MNIST Data reduced with PCA)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
